---
title: "Predict Price Freeze Likelihood: A Bayesian Approach to predict Grocery Pricing in Canada"
author: 
  - Zeyi Cai
thanks: "Code and data are available at:"
date: today
date-format: long
abstract: "This article aims to study the possibility of Canada adopting a price freeze strategy for specific products from November to February of the following year.  By selecting relevant data such as the historical price and current price of specific products in several major groceries, and fitting the Bayesian model for price prediction, the impact of historical prices and time changes on the current price trend is analysed. The flexibility of the Bayesian model enables it to quantify uncertainty stably and reliably, and is superior to the traditional linear regression model in terms of predicting accuracy and interpretability of future price changes. The Posterior predictive checks confirmed the consistency of the model with the observed price distribution, and the confidence interval further revealed the potential variability. The results of the study show that the price freeze may continue from November to February of the following year, but the differences between different suppliers, especially the price coordination and potential collusion between food retailers implied by the extreme values, need continuous attention."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

#### Workspace setup ####
set.seed(304)
library(tidyverse)
library(lubridate)
library(rstanarm)
library(readr)
library(dplyr)
library(ggplot2)
library(bayesplot)
library(knitr)
```


# Introduction
Implementing a price freeze on grocery products for a period of time has become a common annual strategy for Canadian retailers. During the price freeze period, these groceries would keep the prices of certain products unchanged for a period of time, without being affected by market fluctuation, cost changes or other factors, which is a short-term behavior implemented by major retailers in order to stabilize consumer prices and achieve benefits. Well-known supermarket chains such as Loblaws and Metro have always followed this strategy. These retailers aim to protect consumers' ability to pay in the event of economic fluctuations, so as to retain customers and obtain benefits. However, the bread price manipulation scandal that broke out a few years ago also raised questions about the consistency and sustainability of the strategy[@charlebois2023grocers]. Accusations of food price manipulation are also emerging in various countries, such as lowering the price to the original price or higher after the price increase, and using short-term price increases to create falsely high "original prices" to fake the illusion of discounts[@accc2024woolworthscoles].

The analysis uses data such as the history and current price of whole wheat bread from multiple suppliers, focussing on factors such as unit price and its historical changes. By analyzing historical price trends and using Bayesian modelling to predict current price stability, we will explore whether the price freeze strategies of major retail stores will be implemented from November to February of the following year as stated by Metro. By comparing the Bayesian model with the traditional linear regression model, it is shown that the Bayesian method has obvious advantages in integrating uncertainty and capturing the dynamics of price trends. In addition, the performance of the model on historical price data is tested through posterior distribution, so as to improve the reliability of future price forecasts[@nature2020bayesia]. This study provides in-depth insights into understanding the factors affecting prices, and a reference for consumers, regulators, retailers and policymakers to ensure price stability under the pressure of inflation, ensure fair market competition, and prevent price manipulation from harming the interests of consumers.


### Overview

This study explores whether some well-known Canadian food groceries follow the price freeze strategy when pricing whole wheat bread from November to February of the following year. By using old and current price data, we analyzed the relationship between old price, unit price, and current pricing trends of multiple vendors. The study uses the Bayesian regression model to capture these dynamic relationships, and by comparison with the linear regression model, the analysis shows the excellent performance of the Bayesian model through posterior predictive check and credible intervals.


### Estimand
The primary estimand in this analysis is based on the historical price and unit price and the expected price of the whole wheat bread of different vendors from November to February of the following year. It aims to quantify the relationship between these predictors and the current price to assess whether the groceries comply with the price freeze strategy.

It reflects the size of the factors affecting the historical price (\(old\_price\)) and unit price (\(price\_per\_unit\)) on the current price (\(current\_price\)), while controlling the variability between vendors. In order to achieve this goal, the analysis adopts the Bayesian regression model, which combines a priori knowledge and evaluates the uncertainty in these relationships through credible intervals. And the phenomenon of deviating from the predicted pricing trend is interpreted as a possible inconsistency in the price freeze strategy.


```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl_preview
#| tbl-cap: ""

#### Combine the csv. file ####
# Read the CSV files
raw <- read.csv("~/Desktop/grocery_price_freeze/data/01-raw_data/raw.csv", stringsAsFactors = FALSE)
product <- read.csv("~/Desktop/grocery_price_freeze/data/01-raw_data/product.csv", stringsAsFactors = FALSE)

# Combine the files
raw_data <- left_join(raw, product, by = c("product_id"="id"))

# Save the combined file
write.csv(raw_data, "~/Desktop/grocery_price_freeze/data/01-raw_data/raw_data.csv", row.names = FALSE)
```


### Why It Matters

The analysis of the implementation of the price freeze from November to February of the following year is crucial to protecting consumers from inflationary pressure and price fraud. If this strategy can be implemented legally and in a standardized manner, it can not only ensure consumers' ability to pay, but also enhance the credibility and reputation of groceries, and establish trust between retailers and customers, so as to retain customers to achieve greater benefits. By revealing the performance of major vendors in terms of the consistency of pricing strategies, this study provides policymakers and industry stakeholders with important information about potential irregular behavior involving collusion during the period of price freeze.

In addition, the use of Bayesian modelling method enhances the reliability of research results, and by quantifying uncertainty, the analysis has strong applicability in a dynamic economic environment. The results of this study are especially important for policies and strategies aimed at promoting fair pricing and economic stability during the period of high consumer demand.


# Data {#sec-data}
```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-data_preview
# Remove rows with missing values
cleaned_data <- 
  raw_data |>
    drop_na(current_price, product_id) |>
    mutate(
      current_price = as.numeric(current_price),
      price_per_unit = as.numeric(str_remove_all(price_per_unit, "\\$|/gram|/100g|ea\\.|\\s"))
    )

head(cleaned_data)

#### Save data ####
write_csv(cleaned_data, "~/Desktop/grocery_price_freeze/data/02-analysis_data/analysis_data.csv")
```

## Measurement
	
We use the statistical programming language R [@citeR] and its data analysis and visualization libraries to explore grocery pricing trends across multiple vendors. Our data [@filipp_hammer] consists of historical and current prices for a variety of grocery items, collected from major Canadian retailers. Following the principles outlined in [@tellingstories], we aim to provide a clear and insightful narrative about vendor adherence to seasonal price freeze policies. By leveraging Bayesian regression modeling, we quantify the relationships between historical prices, price per unit, and current pricing while incorporating uncertainty. This approach ensures a nuanced understanding of pricing behaviors during a critical consumer period.

The dataset records the pricing behavior of six major vendors for whole wheat bread: Voila, Loblaws, Metro, T&T, NoFrills, SaveOnFoods. The current price at each point in time in the dataset reflects the pricing strategies of different vendors, covering the period from April to June this year for comparative analysis and prediction.

In order to ensure accuracy, the price data has been standardized in the measurement unit, and the product is 675g of whole wheat bread, which makes the comparison between different products and vendors meaningful. For the missing old price data of some products, it is not cleaned and filtered in the initial analysis data to maintain the integrity of the dataset and avoid the introduction of significant deviations. And a few outliers are analyzed separately to assess their impact on the overall trend.

The following packages were used for this study:

- **`tidyverse`** [@tidyverse]: A collection of tools for data manipulation and visualization.
- **`ggplot2`** [@ggplot2]: Creates customizable, high-quality plots. 
- **`readr`** [@readr]: Reads data files quickly and easily. 
- **`lubridate`** [@lubridate]: Simplifies handling dates and times.
- **`dplyr`** [@dplyr]: Makes data manipulation fast and intuitive.
- **`bayesplot`** [@bayesplot]: Visualizes Bayesian model outputs.
- **`rstanarm`** [@rstanarm]: Enables Bayesian regression modeling with Stan.
- **`knitr`** [@knitr]: Combines R code and text for reproducible reports.
- **_Telling Stories with Data_** [@tellingstories]: Referenced for its code and methodologies in data and statistical information.

## Variables
  - `product_id`: A unique identifier for each product in the dataset.
  - `nowtime`: The timestamp indicating when the price was recorded.
  - `current_pricet`: The price of the product at the time of data collection.
  - `old_price`: The previous price of the product, if available.
  - `other`: Promotion for the product in the specific time 
  - `price_per_unit`: The unit price of the product
  - `product_description`: A detailed description of the product, including brand and product specifics.
  - `vendor`: The name of the vendor supplying the product.
  - `product_name`: The name of the product as displayed in the dataset.
  - `units`: The quantity or size of the product in its packaging.
 
Detailed information about these variables and the data structure is presented in @.

```{r}
#| label: fig-planes
#| fig-cap: Relationship between wing length and width
#| echo: false
#| warning: false
#| message: false

analysis_data <- read_csv(here::here("data/02-analysis_data/analysis_data.csv"))

```

```{r}
#| label: tbl-outcome-summary
#| tbl-cap: Summary statistics for current and old prices
#| echo: false

# Summary table of current and old prices
analysis_data %>%
  summarise(
    Avg_Current_Price = mean(current_price, na.rm = TRUE),
    Avg_Old_Price = mean(old_price, na.rm = TRUE),
    Min_Current_Price = min(current_price, na.rm = TRUE),
    Max_Current_Price = max(current_price, na.rm = TRUE),
    Min_Old_Price = min(old_price, na.rm = TRUE),
    Max_Old_Price = max(old_price, na.rm = TRUE)
  ) %>%
  knitr::kable(caption = "Summary of Current and Old Prices")

```
@tbl-outcome-summary shows the summary statistics data of current and old price.

```{r}
#| label: fig-price-comparison
#| fig-cap: Comparison of current and old prices by vendor
#| echo: false
#| warning: false

# Filter data with valid old prices
price_data <- analysis_data %>%
  filter(!is.na(old_price)) %>%
  select(vendor, current_price, old_price)

# Pivot data for plotting
price_comparison <- price_data %>%
  pivot_longer(cols = c(current_price, old_price), names_to = "price_type", values_to = "price")

# Plot the comparison
ggplot(price_comparison, aes(x = vendor, y = price, fill = price_type)) +
  geom_bar(stat = "identity", position = "dodge", alpha = 0.8) +
  scale_fill_manual(values = c("current_price" = "steelblue", "old_price" = "darkorange"),
                    labels = c("Current Price", "Old Price")) +
  theme_minimal() +
  labs(x = "Vendor", y = "Price", fill = "Price Type",
       title = "Comparison of Current and Old Prices by Vendor") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

@fig-price-comparison compares the current and old prices of five vendors, Loblaws, Metro, No Frills, SaveOnFoods and T&T, revealing the pricing trends and changes of each vendor. Among them, the current price of the whole wheat bread in Metro has not changed, indicating the continuity of its pricing, and there is no special offer during this period; the current price of the bread in No Frills is significantly higher than the old price, which shows that its pricing has changed significantly, but combined with the data analysis just now, it may be affected by extreme values; The current price of SaveOnFoods and T&T is lower than the old price, which may reflect the price adjustment during the promotion. Generally speaking, the price stability of the whole wheat bread in Metro provides consumers with a clear shopping experience, while the price fluctuations of No Frills need close attention. The price reduction trend of SaveOnFoods and T&T may be the result of market competition triggered by other groceries' promotional activities.

## Predictor variables

Add graphs, tables and text.

Use sub-sub-headings for each outcome variable and feel free to combine a few into one if they go together naturally.
```{r}
#| label: tbl-predictors
#| tbl-cap: Summary statistics for predictor variables
#| echo: false

# Summary table of predictor variables
analysis_data %>%
  group_by(vendor) %>%
  summarise(
    Avg_Price = mean(current_price, na.rm = TRUE),
    Min_Price = min(current_price, na.rm = TRUE),
    Max_Price = max(current_price, na.rm = TRUE),
    Count = n()
  ) %>%
  knitr::kable(caption = "Summary of Pricing by Vendor")
```

@tbl-predictors summarizes the average price, lowest price and highest price of six suppliers of Loblaw, Metro, No Frills, SaveOnFoods, T&T and Voila in a fixed period of time.

```{r}
#| label: fig-predictor-vendor
#| fig-cap: Price distribution by vendor
#| echo: false
#| warning: false
# Scatterplot to show price distribution by vendor
ggplot(analysis_data, aes(x = vendor, y = current_price, color = vendor)) +
  geom_point(position = position_jitter(width = 0.2), alpha = 0.6) +
  theme_minimal() +
  labs(
    title = "Price Distribution by Vendor",
    x = "Vendor",
    y = "Current Price",
    color = "Vendor"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```
@fig-predictor-vendor shows the price distribution of six vendors: Loblaws, Metro, No Frills, Save-On-Foods, T&T and Voila. The prices of Loblaws, Metro and T&T are concentrated between $3 and $4.5, with less volatility, indicating the stability of their pricing. The price of Save-On-Foods is concentrated in the range of $4 to $5, while the price of Voila is fixed at $5, both of which reflect high stability and are consistent with the freezing policy. In comparison, the price of No Frills fluctuates significantly, from less than $1 to nearly $7, showing the possibility of promotional or strategic pricing, indicating that it may have a lower degree of compliance with the price freeze policy in the future. In addition, No Frills still has obvious abnormal values, while other suppliers have fewer abnormal values. Overall, Loblaws, Metro, Save-On-Foods, T&T and Voila showed high compliance during the price freeze, while No Frills adopted a more flexible pricing strategy. This analysis reflects the important impact of supplier pricing strategies on consumer experience and emphasizes the need to focus on monitoring vendors with large price fluctuations such as No Frills.

```{r}
#| label: fig-vendor-time-pricing
#| fig-cap: Interaction between vendor, time, and pricing
#| echo: false
#| warning: false

# Convert `nowtime` to a date-time object for proper ordering
analysis_data <- analysis_data %>%
  mutate(nowtime = lubridate::ymd_hms(nowtime))

# Line plot showing vendor and time interaction with pricing
ggplot(analysis_data, aes(x = nowtime, y = current_price, color = vendor)) +
  geom_line(alpha = 0.7, size = 1) +
  scale_color_brewer(palette = "Set1") +
  theme_minimal() +
  labs(x = "Time", y = "Current Price", color = "Vendor",
       title = "Vendor-Time Interaction with Pricing",
       subtitle = "Tracking price changes over time for each vendor") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```
@fig-vendor-time-pricing shows the price fluctuation trend of six vendors of Loblaw, Metro, No Frills, SaveOnFoods, T&T and Voila. The price fluctuation of Loblaws and Metro is extremely small, showing remarkable stability. The price of No Frills fluctuates greatly, and there are significant peaks during this period, which shows that there may be challenges to its stability during the price freeze period. The price adjustment trend of SaveOnFoods and T&T is relatively moderate and fluctuates moderately. Voila's price is the most consistent throughout the year, indicating that it has adopted a strict pricing strategy. On the whole, most vendors have achieved a stable price adjustment by November.

# Model
```{r}
#| warning: false
#| message: false
#| echo: false
#### Read data ####
analysis_data <- read_csv("~/Desktop/grocery_price_freeze/data/02-analysis_data/analysis_data.csv", 
                          show_col_types = FALSE)
analysis_data <- analysis_data %>%
  filter(!is.na(price_per_unit), !is.na(old_price)) %>%
  sample_n(50)

# Verify the number of rows
cat("Number of rows in the dataset:", nrow(analysis_data), "\n")

# Inspect the first few rows
head(analysis_data)
```

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#### Fit a Bayesian regression model ####
bayesian_model <- stan_glm(
  formula = current_price ~ price_per_unit + old_price,
  data = analysis_data,
  family = gaussian(),
  prior = normal(location = 1, scale = 0.5, autoscale = TRUE),
  prior_intercept = normal(location = 0, scale = 0.5, autoscale = TRUE),
  prior_aux = exponential(rate = 1, autoscale = TRUE),
  seed = 302  # Set seed for reproducibility
)

#### Fit a Linear Regression Model ####
linear_regression_model <- lm(current_price ~ price_per_unit + old_price, data = analysis_data)

head(bayesian_model)
head(linear_regression_model)
```

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
# View summary of the bayesian model
summary(bayesian_model)
plot(bayesian_model)

# View summary of the linear model
summary(linear_regression_model)
plot(linear_regression_model)
```


```{r}
#| eval: false
#| echo: false
#| message: false
#| warning: false
#### Save Model ####
# Save the fitted model
saveRDS(bayesian_model, file = "~/Desktop/grocery_price_freeze/models/bayesian_model.rds")
saveRDS(linear_regression_model, file = "~/Desktop/grocery_price_freeze/models/linear_regression_model.rds")
```

```{r}
#| echo: false
#| message: false
#| warning: false
#### Generate Predictions ####
# Add Bayesian model predictions
analysis_data <- analysis_data %>%
  mutate(predicted_price_bay = predict(bayesian_model, newdata = analysis_data))
# Add Linear regression model predictions
analysis_data <- analysis_data %>%
  mutate(predicted_price_linear = predict(linear_regression_model, newdata = analysis_data))

# View the updated dataset
head(analysis_data)
```

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-model-predict
#### Plot the Model 
# Plot for Bayesian model
ggplot(analysis_data, aes(x = current_price, y = predicted_price_bay)) +
  geom_point(color = "blue", alpha = 0.6) +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  labs(
    title = "Actual vs Predicted Prices (Bayesian Model)",
    x = "Actual Price",
    y = "Predicted Price"
  ) +
  theme_minimal()

# Plot for Linear model
ggplot(analysis_data, aes(x = current_price, y = predicted_price_linear)) +
  geom_point(color = "purple", alpha = 0.6) +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  labs(
    title = "Actual vs Predicted Prices (Linear Model)",
    x = "Actual Price",
    y = "Predicted Price"
  ) +
  theme_minimal()
```
@fig-model-predict shows that the forecasting price of the Bayesian model is closely concentrated near the straight line, especially in the lower price range, and the actual price and the predicted value show a high degree of consistency. When the actual price is higher, the model is obviously underestimated, indicating that it has limitations in capturing high price outliers. The Bayesian method is especially important in analysing volatile scenarios such as price freezing periods through built-in uncertainty processing (such as a prior distribution and credible intervals).

@fig-model-predict indicates the distribution of the predicted price of the linear regression model around the straight line is relatively scattered, especially in the medium actual price range, and the prediction accuracy is lower than that of the Bayesian model. And the model failed to accurately capture the abnormal value. The linear regression model assumes that there is a fixed relationship between the predictor and the response variable, which is difficult to adapt to nonlinear dynamics.

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-residual-distri
# Calculate Residuals
analysis_data <- analysis_data %>%
  mutate(
    residual_bay = current_price - predicted_price_bay,
    residual_linear = current_price - predicted_price_linear
  )

# Plot Residuals
residual_data <- analysis_data %>%
  pivot_longer(cols = c(residual_bay, residual_linear), names_to = "model", values_to = "residual") %>%
  mutate(model = recode(model, "residual_bay" = "Bayesian", "residual_linear" = "Linear"))

ggplot(residual_data, aes(x = residual, fill = model)) +
  geom_histogram(alpha = 0.6, position = "identity", bins = 20) +
  labs(
    title = "Residual Distribution for Bayesian and Linear Models",
    x = "Residual",
    y = "Count",
    fill = "Model"
  ) +
  theme_minimal()

# Residuals vs. Predicted Values for Bayesian Model
ggplot(analysis_data, aes(x = predicted_price_bay, y = residual_bay)) +
  geom_point(alpha = 0.6, color = "blue") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(
    title = "Residuals vs Predicted Values (Bayesian Model)",
    x = "Predicted Price",
    y = "Residual"
  ) +
  theme_minimal()

# Residuals vs. Predicted Values for Linear Model
ggplot(analysis_data, aes(x = predicted_price_linear, y = residual_linear)) +
  geom_point(alpha = 0.6, color = "purple") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(
    title = "Residuals vs Predicted Values (Linear Model)",
    x = "Predicted Price",
    y = "Residual"
  ) +
  theme_minimal()
```
@fig-residual-distri uses the Bayesian model, and its residuals are closely concentrated near zero, indicating that the prediction accuracy of most data points is high.

Although most of the residuals in the linear model are close to zero, there is a significant long tail in the positive residual, reflecting the poor prediction effect of some observations.
In general, the residual distribution of the Bayesian model is more symmetrical and concentrate, indicating that the deviation is smaller and the prediction is more reliable.

In terms of residual and predicted value, the residual of the Bayesian model is well distributed around the red line, and there is no obvious pattern, which shows that the model fits well. A small number of large residuals show that the Bayesian model is slightly insufficient in dealing with outliers, but the overall performance is still strong.

Compared with the Bayesian model, the linear model has a more scattered residual distribution, especially in the area of higher predicted values. The residual of some predicted prices is large, indicating that the linear model is not flexible enough in capturing complex relationships.

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
# Calculate RMSE for both models
rmse_bayesian <- sqrt(mean((analysis_data$current_price - analysis_data$predicted_price_bay)^2))
rmse_linear <- sqrt(mean((analysis_data$current_price - analysis_data$predicted_price_linear)^2))

cat("RMSE for Bayesian Model:", rmse_bayesian, "\n")
cat("RMSE for Linear Model:", rmse_linear, "\n")
```

```{r}
#| label: fig-bay-ci
#| eval: true
#| echo: false
#| message: false
#| warning: false

# Extract Bayesian credible intervals
bayesian_intervals <- posterior_predict(bayesian_model, newdata = analysis_data, draws = 1000)
bayesian_ci <- apply(bayesian_intervals, 2, quantile, probs = c(0.025, 0.975))

# Add to data
analysis_data <- analysis_data %>%
  mutate(
    bayesian_ci_lower = bayesian_ci[1, ],
    bayesian_ci_upper = bayesian_ci[2, ]
  )

# Plot Credible Intervals
ggplot(analysis_data, aes(x = current_price, y = predicted_price_bay)) +
  geom_point(color = "blue", alpha = 0.6) +
  geom_errorbar(aes(ymin = bayesian_ci_lower, ymax = bayesian_ci_upper), color = "orange", width = 0.2) +
  labs(
    title = "Bayesian Credible Intervals for Predicted Prices",
    x = "Actual Price",
    y = "Predicted Price"
  ) +
  theme_minimal()
```

@fig-bay-ci shows the uncertainty of price forecasting through forecast values and 90% confidence intervals, providing decision-makers with rich forecasting information and helping to evaluate the reliability and potential risks of price forecasting, especially in the uncertain scenario of price freezing. In contrast, the linear model lacks the ability to handle uncertainty and outliers, and it is difficult to meet the needs of price decision-making in the dynamic market. Therefore, the Bayesian model is superior in price freeze analysis.

### Model justification

# Results

@smy-bay-model shows a significant pattern between the current price (current_price) and the past price (old_price). The Bayesian model incorporates uncertainty when estimating the impact of these predictors on current prices. The following table summarizes the coefficient estimates and shows the reliability of these estimates through the 90% confidence interval.

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: smy-bay-model
# Load the Bayesian model
bayesian_model <- readRDS("~/Desktop/grocery_price_freeze/models/bayesian_model.rds")

# Print summary of the model to inspect the results
print(summary(bayesian_model))
```

@tbl-coeff-est provides the coefficient estimates for the predictors current_price and old_price, with a baseline intercept:
```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: tbl-coeff-est
# Generate a data frame of the coefficient summary
model_summary_df <- data.frame(
  Parameter = c("Intercept", "Current Price", "Old Price"),
  Mean = c(3.56, 1.78, 0.72),
  SD = c(0.17, 0.14, 0.12),
  `2.5%` = c(3.23, 1.50, 0.50),
  `50%` = c(3.55, 1.78, 0.72),
  `97.5%` = c(3.89, 2.06, 0.94)
)

# Display table with kable
kable(model_summary_df, format = "markdown", align = "c", col.names = c("Parameter", "Mean", "SD", "2.5%", "50%", "97.5%"))
```

The intercept shows that the current price forecast has a strong starting point, and the average coefficient of the current price is 1.78, showing a significant positive correlation, indicating that the current price level is strongly affected by its previous state. This result shows that the pricing trend is continuous and emphasizes the importance of current price in forecasting. The positive coefficient of the old price was 0.72, indicating that the historical price trend has also played a certain role in predicting the current price, but its impact is smaller than that of the current price. This shows that although prices have contributed to forecasts in the past, their impact is relatively limited.

To visualize the uncertainty around the coefficient estimates, Figure @fig-model_coefficients displays the 90% credible intervals for current_price and old_price.
```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-model_coefficients

# Extract posterior samples
posterior_samples <- as.array(bayesian_model)

# Plot 90% credible intervals for the coefficients
color_scheme_set("brightblue")
mcmc_intervals(
  posterior_samples,
  prob = 0.9
) +
  labs(
    title = "Model Coefficients",
    subtitle = "90% Credible Intervals",
    x = "Coefficient Estimate",
    y = "Predictors"
  ) +
  theme_minimal()

```

@fig-model_coefficients provides an a posterior mean estimate and a credible interval, which comprehensively demonstrates the impact of current price and past price on pricing: the current price has a greater impact, highlighting its future importance of price prediction. Although the impact of the old price is relatively small, it still shows a positive impact, indicating that the old price affects the current pricing to a certain extent, but the effect is relatively weak.
The confidence interval shows the accuracy and variability of these estimates.

# Discussion


## Weaknesses and next steps
On the whole, the Bayesian model performs well in most price ranges, but a few large residuals indicate that the Bayesian model is slightly insufficient in dealing with outliers. Although the diffusion of its simulated distribution reflects the solid handling of uncertainty during the price freeze, the small peaks in the high price range are insufficiently captured, which may need It should be improved by introducing more predictive variables or optimising the a priori distribution. And before using the Bayesian model, it is necessary to reduce the data sample to a certain value in order to accurately compare the fitting performance of the Bayesian model and the linear model, which will lead to insufficient samples and possible predictive deviations. In future research, it is necessary to consider the screening of data in more careful and multi-ways before fitting the model.

\newpage

\appendix

# Appendix 


# Additional data details

## Pollster Methodology

The polling method of this study focuses on designing a systematic process to collect price data of whole wheat bread from Canadian vendors during the price freeze from November to February of the following year. The specific method includes the following key elements:

The survey aims to assess the implementation of the price freeze policy of major Canadian grocery suppliers from November to February of the following year. The target group covers suppliers and consumers, and the data collection covers major grocery chains such as Loblaws, Metro, No Frills, Save-On-Foods, T&T and Voila. The questionnaire adopts stratified sampling technology to ensure that data is collected proportionally from different suppliers and regions, and randomly sampled at each level to reduce deviation and ensure diversity. Online questionnaires can also be distributed by email and social media advertisements, and physical store data is collected by the on-site survey team to verify the results of the questionnaire. In addition, collect supplementary data from the supplier's official website to ensure the comprehensiveness and accuracy of the data. The questionnaire design is concise and clear to ensure the standardisation of price records and provide detailed record descriptions for different product categories. In the process of data processing, the data quality is reliable by marking and processing abnormal values, filling in the missing data if necessary, and cross-verifying the data reported by suppliers and consumers. This multi-level survey design and rigourous data processing method are conducive to comprehensive and accurate analysis of the implementation of price freeze policies and provide a basis for policy formulation and consumers.

## Idealized Methodology
In order to ensure the accuracy, reliability and reproducibility of data collection and analysis, this idealized method is designed to be more comprehensive and theoretically rigourous. First of all, by covering the entire market, including all Canadian suppliers, online platforms and small independent grocery stores, ensure a comprehensive reflection of the market situation; secondly, integrate multiple data sources, including questionnaire results, real-time network capture data, historical archiving and transaction data, and combine with third-party data sets for background comparison. Compare. Advanced sampling technology adopts multi-stage sampling and dynamically adjusts the sample scale to improve the representative of areas with insufficient data coverage. Use simulation-based methods to test the reliability of data in situations such as inflation shocks or supply chain interruptions, and link the survey results with the Bayesian model to optimise the forecast and improve the accuracy of the model. In terms of data ethics and transparency, disclose data collection agreements and anonymize data sets to ensure that the public can review and comply with data protection regulations. This method can not only capture accurate and detailed price data, but also set an industry benchmark for observational data collection, realizing a seamless connection with advanced statistics and econometric models, thus providing high-value operational insights.

## Designing a Survey for Grocery Pricing Data Collection
### Objective
The objective of the survey is to collect detailed price data of grocery products from multiple Canadian suppliers to evaluate and predict their compliance with the price freeze strategy from November to February of the following year. These data will provide references for price changes, outliers and trends, and will become the basis for statistical analysis and Bayesian analysis.

# Survey and design

### Target respondents

Manager of food and grocery store:

Responsible for the pricing of suppliers such as Loblaws, Metro, No Frills, Save-On-Foods, T&T and Voila.

Consumers:

Consumers who regularly buy food and groceries can get the price through receipts.

Online shopping platform:

Price information can be collected from the online food and grocery platform.

### Data collection method

Main methods:

Design structured online and offline questionnaires and distribute them to the target respondents.

The following essential methods:

Obtain additional price data from the supplier's official website to verify the data and expand the data range.

### Questionnaire content

Part I: Basic Information

What is your city?

What is your identity? ( Choice: relevant food and grocery store staff, consumers, others)

Part II: Supplier Information

What is the food and grocery supplier you reported? ( Choice: Loblaws, Metro, No Frills, Save-On-Foods, T&T, Voila, etc.)

These price data come from:

Physical store

Online store

Others (please indicate)

The third part: Product price

Please list the prices of the following products:

[Name of whole wheat bread 1]

[Name of whole wheat bread 2]

[Name of whole wheat bread 3]

Please indicate the unit price of each product (if applicable).

Part IV: Historical Price

Do you have the historical price data of these products? If so, please provide the following information:

Product name

Last month's price

Price 3 months ago

Part 5: Price Freeze Observation

Have you noticed that the price of the above products has been frozen? ( Yes/No)

Have you observed any price fluctuations or promotional activities? If there is, please specify.

### Sample strategy

Sample frame:

Major food and grocery suppliers in Canada, and representative consumer samples from different cities.

Sample extraction method:

Stratified sampling: Ensure that data is collected from all major suppliers.

Random sampling: collect the price data reported by consumers to reduce the deviation.

Sample scale:

The target is 800-1,000 questionnaires to ensure even distribution among people under various conditions.

### Data verification

Cross-verification by the price reported by the consumer with the data reported by the supplier and the official online price.

Use the network as an auxiliary source for data verification.

### ethic considerations

Before collecting data, the consent of the interviewee is required.

Ensure data privacy and anonymise the respondent's information.

Connection with literature

This survey is based on the method design in the market research literature, especially the relevant research on consumer price sensitivity research and supplier pricing strategies in the field of food and grocery retail. By integrating the principle of observing data collection and ensuring the rigour of methodology, this questionnaire can provide high-quality data support for subsequent analysis.


## Posterior predictive check

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]
#### Posterior Predictive Check ####
# Draw samples from the posterior predictive distribution
pp_check(bayesian_model, nsamples = 100) +
  ggtitle("Posterior Predictive Check: Distribution of Current Price")

```
@fig-ppcheckandposteriorvsprior (PPC) shows that the Bayesian model can well show the distribution characteristics of the current price and reflect its reliability in price prediction. The observation data (dark blue line) is highly consistent with the central trend of the simulation data (light blue line), indicating that the model accurately captures the overall shape of the main price range. However, the simulation distribution is slightly diffused around the observation distribution, reflecting the effective quantification of uncertainty in the model. However, there are certain limitations on the modelling of extreme values or abnormal values. At the same time, the tail of the simulation distribution is slightly beyond the scope of observation data, indicating that the model tries to incorporate potential outliers or incompletely reflected variability.

## Diagnostics

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-diagnostics
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2
plot(bayesian_model, "trace")

plot(bayesian_model, "rhat")

```
@fig-diagnostics shows that the Bayesian model has successfully achieved convergence, ensuring that the exploration of the posterior distribution is sufficient and the inference is reliable. In the trace diagram, each parameter shows well-mixed chains, with the samples overlapping and moving freely across the parameter space without sticking. In addition, the chain presents a stable state with no obvious drift or trend, indicating that the sampling process has reached convergence. 
At the same time, the graph shows the values of the parameters are very close to 1, indicating that the difference between the with-chain variance and the between-chain variance is extremely small, which further verifies the convergence of the chain. These results show that the sampling process is sufficient and the posteriori distribution is fully explored. And the reliability of the model can provide a solid basis for parameter analysis and price forecasting during the price freeze. well-mixed , stability and low r values provide strong support for subsequent inferences and decision-making, ensuring that the model results are credible and suitable for pricing analysis in actual situations.

\newpage


# References


