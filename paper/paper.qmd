---
title: "Predict Price Freeze Likelihood: A Bayesian Approach to predict Grocery Pricing in Canada"
author: 
  - Zeyi Cai
thanks: "Code and data are available at:https://github.com/ZeyiCai/grocery_price_freeze_"
date: today
date-format: long
abstract: "This article aims to study the possibility of Canada adopting a price freeze strategy for specific products from November to February of the following year.  By selecting relevant data such as the old price and current price of specific products in several major groceries, and fitting the Bayesian model for price prediction, we analysized the impact of old prices and time changes on the current price trend. The flexibility of the Bayesian model enables it to quantify uncertainty stably and reliably, and is superior to the traditional linear regression model in terms of predicting accuracy and interpretability of future price changes. The Posterior predictive checks confirmed the consistency of the model with the observed price distribution, and the confidence interval further revealed the potential variability. The results of the study show that the price freeze may continue from November to February of the following year, but the differences between different suppliers, especially the price coordination and potential collusion between food retailers implied by the extreme values, need continuous attention."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

#### Workspace setup ####
set.seed(304)
library(tidyverse)
library(lubridate)
library(rstanarm)
library(readr)
library(dplyr)
library(ggplot2)
library(bayesplot)
library(knitr)
```


# Introduction
Implementing a price freeze on grocery products for a period of time has become a common annual strategy for Canadian retailers. During the price freeze period, these groceries would keep the prices of certain products unchanged for a period of time, without being affected by market fluctuation, cost changes or other factors, which is a short-term behavior taken by major retailers in order to stabilize consumer prices and achieve benefits. Some well-known groceries such as Loblaws and Metro have always followed this strategy. These retailers aim to protect consumers' ability to pay in the event of economic fluctuations, so as to retain customers and obtain benefits. However, the bread price manipulation scandal that broke out a few years ago also raised questions about the consistency and sustainability of the strategy[@charlebois2023grocers]. Accusations of food price manipulation are also emerging in various countries, such as lowering the increased price to the original price or "lowering" to a higher price, which means using short-term price increases to create high "original prices" to fake the illusion of discounts[@accc2024woolworthscoles].

The analysis uses data such as the old price and current price of whole wheat bread from multiple suppliers, focusing on factors such as unit price and its time changes. By analyzing historical price trends and using Bayesian model to predict current price stability, we will explore whether the price freeze strategies of major retail stores will be taken from November to February of the following year as stated by Metro[@charlebois2023grocers]. By comparing the Bayesian model with the traditional linear regression model, it is shown that the Bayesian method has obvious advantages in integrating uncertainty and capturing the dynamics of price trends. In addition, the performance of the model on old price data is tested through posterior distribution, so as to improve the reliability of future price forecasts[@nature2020bayesian]. This study provides in-depth insights into understanding the factors affecting prices, and a reference for consumers, regulators, retailers and policymakers to ensure price stability under the pressure of inflation, ensure fair market competition, and prevent price manipulation from harming the interests of consumers.


### Overview

This study explores whether some well-known Canadian food groceries follow the price freeze strategy when pricing whole wheat bread from November to February of the following year. By using old and current price data, we analyzed the relationship between old price, unit price, and current pricing trends of multiple vendors. The study uses the Bayesian model to capture these dynamic relationships, and by comparison with the linear regression model, the analysis shows the excellent performance of the Bayesian model through posterior predictive check and credible intervals.


### Estimand
The primary estimand in this analysis is based on the old price and unit price and the expected price of the whole wheat bread of different vendors from November to February of the following year. It aims to quantify the relationship between these predictors and the current price to assess whether the groceries comply with the price freeze strategy.

It reflects some factors affecting the old price (\(old\_price\)) and unit price (\(price\_per\_unit\)) on the current price (\(current\_price\)), while controlling the variability between vendors. In order to achieve this goal, the analysis adopts the Bayesian model, which combines a posterior predictive check and evaluates the uncertainty in these relationships through credible intervals. And the phenomenon of deviating from the predicted pricing trend is interpreted as a possible inconsistency in the price freeze strategy.


```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl_preview

#### Combine the csv. file ####
# Read the CSV files
raw <- read.csv("~/Desktop/grocery_price_freeze/data/01-raw_data/raw.csv", stringsAsFactors = FALSE)
product <- read.csv("~/Desktop/grocery_price_freeze/data/01-raw_data/product.csv", stringsAsFactors = FALSE)

# Combine the files
raw_data <- left_join(raw, product, by = c("product_id"="id"))

# Save the combined file
write.csv(raw_data, "~/Desktop/grocery_price_freeze/data/01-raw_data/raw_data.csv", row.names = FALSE)
```


### Why It Matters

The analysis of the practice of the price freeze from November to February of the following year is crucial to protecting consumers from inflationary pressure and price fraud. If this strategy can be taken legally and in a standardized manner, it can not only ensure consumers' ability to pay, but also enhance the credibility and reputation of groceries, and establish trust between retailers and customers, so as to retain customers to achieve greater benefits. By revealing the performance of major vendors in terms of the consistency of pricing strategies, this study provides policymakers and industry stakeholders with important information about potential irregular behavior involving collusion during the period of price freeze.

In addition, the use of Bayesian modelling method enhances the reliability of research results, and by quantifying uncertainty, the analysis has strong applicability in a dynamic economic environment. The results of this study are especially important for policies and strategies aimed at promoting fair pricing and economic stability during the period of high consumer demand.


# Data {#sec-data}
```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-data_preview
# Remove rows with missing values
cleaned_data <- 
  raw_data |>
    drop_na(current_price, product_id) |>
    mutate(
      current_price = as.numeric(current_price),
      price_per_unit = as.numeric(str_remove_all(price_per_unit, "\\$|/gram|/100g|ea\\.|\\s"))
    )

head(cleaned_data)

#### Save data ####
write_csv(cleaned_data, "~/Desktop/grocery_price_freeze/data/02-analysis_data/analysis_data.csv")
```

## Measurement
	
We use the statistical programming language R [@citeR] and its data analysis and visualization libraries to explore grocery pricing trends across multiple vendors. Our data [@filipp_hammer] consists of old and current prices for a variety of grocery items, collected from major Canadian retailers. Following the principles outlined in [@tellingstories], we aim to provide a clear and insightful narrative about whether vendors adhere to price freeze policies. By using Bayesian regression modeling, we quantify the relationships between old prices, price per unit, and current price while incorporating uncertainty. This approach ensures a detailed and complete understanding of pricing behaviors during a critical period.

The dataset records the pricing behavior of six major vendors for whole wheat bread: Voila, Loblaws, Metro, T&T, NoFrills, SaveOnFoods. The current price at each point in time in the dataset reflects the pricing strategies of different vendors, covering the period from April to June this year for comparative analysis and prediction.

In order to ensure accuracy, the price data has been standardized in the measurement unit, and the product is 675g of whole wheat bread, which makes the comparison between different products and vendors meaningful. For the missing old price data of some products, it is not cleaned and filtered in the initial analysis data to maintain the integrity of the dataset and avoid the introduction of significant deviations. And a few outliers are analyzed separately to assess their impact on the overall trend.

The following packages were used for this study:

- **`tidyverse`** [@tidyverse]: A collection of tools for data manipulation and visualization.
- **`ggplot2`** [@ggplot2]: Creates customizable, high-quality plots. 
- **`readr`** [@readr]: Reads data files quickly and easily. 
- **`lubridate`** [@lubridate]: Simplifies handling dates and times.
- **`dplyr`** [@dplyr]: Makes data manipulation fast and intuitive.
- **`bayesplot`** [@bayesplot]: Visualizes Bayesian model outputs.
- **`rstanarm`** [@rstanarm]: Enables Bayesian regression modeling with Stan.
- **`knitr`** [@knitr]: Combines R code and text for reproducible reports.
- **_Telling Stories with Data_** [@tellingstories]: Referenced for its code and methodologies in data and statistical information.

## Variables
  - `product_id`: A unique identifier for each product in the dataset.
  - `nowtime`: The timestamp indicating when the price was recorded.
  - `current_pricet`: The price of the product at the time of data collection.
  - `old_price`: The previous price of the product, if available.
  - `other`: Promotion for the product in the specific time 
  - `price_per_unit`: The unit price of the product
  - `product_description`: A detailed description of the product, including brand and product specifics.
  - `vendor`: The name of the vendor supplying the product.
  - `product_name`: The name of the product as displayed in the dataset.
  - `units`: The quantity or size of the product in its packaging.
 
Detailed information about these variables and the data structure is presented in @filipp_hammer.

```{r}
#| label: fig-planes
#| fig-cap: Relationship between wing length and width
#| echo: false
#| warning: false
#| message: false

analysis_data <- read_csv(here::here("data/02-analysis_data/analysis_data.csv"))

```

```{r}
#| label: tbl-outcome-summary
#| tbl-cap: Summary statistics for current and old prices
#| echo: false

analysis_data %>%
  summarise(
    Avg_Current_Price = mean(current_price, na.rm = TRUE),
    Avg_Old_Price = mean(old_price, na.rm = TRUE),
    Min_Current_Price = min(current_price, na.rm = TRUE),
    Max_Current_Price = max(current_price, na.rm = TRUE),
    Min_Old_Price = min(old_price, na.rm = TRUE),
    Max_Old_Price = max(old_price, na.rm = TRUE)
  ) %>%
  knitr::kable(caption = "Summary of Current and Old Prices")

```
@tbl-outcome-summary shows the summary statistics data of current and old price.

```{r}
#| label: fig-price-comparison
#| fig-cap: Comparison of current and old prices by vendor
#| echo: false
#| warning: false

# Filter data with valid old prices
price_data <- analysis_data %>%
  filter(!is.na(old_price)) %>%
  select(vendor, current_price, old_price)

# Pivot data for plotting
price_comparison <- price_data %>%
  pivot_longer(cols = c(current_price, old_price), names_to = "price_type", values_to = "price")

# Plot the comparison
ggplot(price_comparison, aes(x = vendor, y = price, fill = price_type)) +
  geom_bar(stat = "identity", position = "dodge", alpha = 0.8) +
  scale_fill_manual(values = c("current_price" = "steelblue", "old_price" = "darkorange"),
                    labels = c("Current Price", "Old Price")) +
  theme_minimal() +
  labs(x = "Vendor", y = "Price", fill = "Price Type",
       title = "Comparison of Current and Old Prices by Vendor") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

@fig-price-comparison compares the current and old prices of five vendors, Loblaws, Metro, No Frills, SaveOnFoods and T&T, revealing the pricing trends and changes of each vendor. Among them, the current price of the whole wheat bread in Metro has not changed, indicating the continuity of its pricing, and there is no special offer during this period; the current price of the bread in No Frills is significantly higher than the old price, which shows that its pricing has changed significantly, but combined with the data analysis just now, it may be affected by extreme values. The current price of SaveOnFoods and T&T is lower than the old price, which may reflect the price adjustment during the promotion. Generally speaking, the price of the whole wheat bread in Metro is stable, while the price fluctuations of No Frills need close attention. The price reduction trend of SaveOnFoods and T&T may be the result of market competition triggered by other groceries' promotional activities.

## Predictor variables

```{r}
#| label: tbl-predictors
#| tbl-cap: Summary statistics for predictor variables
#| echo: false

analysis_data %>%
  group_by(vendor) %>%
  summarise(
    Avg_Price = mean(current_price, na.rm = TRUE),
    Min_Price = min(current_price, na.rm = TRUE),
    Max_Price = max(current_price, na.rm = TRUE),
    Count = n()
  ) %>%
  knitr::kable(caption = "Summary of Pricing by Vendor")
```

@tbl-predictors summarizes the average price, lowest price and highest price of six suppliers of Loblaw, Metro, No Frills, SaveOnFoods, T&T and Voila in a fixed period of time.

```{r}
#| label: fig-predictor-vendor
#| fig-cap: Price distribution by vendor
#| echo: false
#| warning: false
# Scatterplot to show price distribution by vendor
ggplot(analysis_data, aes(x = vendor, y = current_price, color = vendor)) +
  geom_point(position = position_jitter(width = 0.2), alpha = 0.6) +
  theme_minimal() +
  labs(
    title = "Price Distribution by Vendor",
    x = "Vendor",
    y = "Current Price",
    color = "Vendor"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```
@fig-predictor-vendor shows the price distribution of six vendors: Loblaws, Metro, No Frills, Save-On-Foods, T&T and Voila. The prices of Loblaws, Metro, Save-On-Foods and T&T are concentrated between $3 and $5, indicating the stability of their pricing, while the price of Voila is fixed at $5, 
both of which reflect high stability and are consistent with the freezing policy. In comparison, the price of No Frills fluctuates significantly, from less than $1 to nearly $11, indicating that it may have a lower possibility for the grocery to take the price freeze policy in the future since No Frills has obvious abnormal values, while other suppliers have fewer abnormal values. Overall, Loblaws, Metro, Save-On-Foods, T&T and Voila showed high compliance during the price freeze, while No Frills adopted a more flexible pricing strategy. This analysis reflects the important impact of supplier pricing strategies on consumer experience and emphasizes the need to focus on monitoring vendors with large price fluctuations such as No Frills.

```{r}
#| label: fig-vendor-time-pricing
#| fig-cap: Interaction between vendor, time, and pricing
#| echo: false
#| warning: false

# Convert `nowtime` to a date-time object for proper ordering
analysis_data <- analysis_data %>%
  mutate(nowtime = lubridate::ymd_hms(nowtime))

# Line plot showing vendor and time interaction with pricing
ggplot(analysis_data, aes(x = nowtime, y = current_price, color = vendor)) +
  geom_line(alpha = 0.7, size = 1) +
  scale_color_brewer(palette = "Set1") +
  theme_minimal() +
  labs(x = "Time", y = "Current Price", color = "Vendor",
       title = "Vendor-Time Interaction with Pricing",
       subtitle = "Tracking price changes over time for each vendor") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```
@fig-vendor-time-pricing shows the price fluctuation trend of six vendors of Loblaws, Metro, No Frills, SaveOnFoods, T&T and Voila. The price fluctuation of Loblaws and Metro is extremely small, showing remarkable stability. The price of No Frills fluctuates greatly, and there are significant peaks during this period, which shows that there may be challenges to its stability during the price freeze period. The price adjustment trend of SaveOnFoods and T&T is relatively moderate and Voila's price is the most consistent throughout the year, indicating that it has adopted a strict pricing strategy. On the whole, most vendors have achieved a stable price adjustment by November.

# Model
```{r}
#| warning: false
#| message: false
#| echo: false
#### Read data ####
analysis_data <- read_csv("~/Desktop/grocery_price_freeze/data/02-analysis_data/analysis_data.csv", 
                          show_col_types = FALSE)
analysis_data <- analysis_data %>%
  filter(!is.na(price_per_unit), !is.na(old_price)) %>%
  sample_n(50)

# Verify the number of rows
cat("Number of rows in the dataset:", nrow(analysis_data), "\n")

# Inspect the first few rows
head(analysis_data)
```

```{r}
#| echo: false
#| message: false
#| warning: false
#### Fit a Bayesian regression model ####
bayesian_model <- stan_glm(
  formula = current_price ~ price_per_unit + old_price,
  data = analysis_data,
  family = gaussian(),
  prior = normal(location = 1, scale = 0.5, autoscale = TRUE),
  prior_intercept = normal(location = 0, scale = 0.5, autoscale = TRUE),
  prior_aux = exponential(rate = 1, autoscale = TRUE),
  seed = 302  # Set seed for reproducibility
)

#### Fit a Linear Regression Model ####
linear_regression_model <- lm(current_price ~ price_per_unit + old_price, data = analysis_data)

head(bayesian_model)
head(linear_regression_model)
```

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
# View summary of the bayesian model
summary(bayesian_model)
plot(bayesian_model)

# View summary of the linear model
summary(linear_regression_model)
plot(linear_regression_model)
```


```{r}
#| eval: false
#| echo: false
#| message: false
#| warning: false
#### Save Model ####
# Save the fitted model
saveRDS(bayesian_model, file = "~/Desktop/grocery_price_freeze/models/bayesian_model.rds")
saveRDS(linear_regression_model, file = "~/Desktop/grocery_price_freeze/models/linear_regression_model.rds")
```

```{r}
#| echo: false
#| message: false
#| warning: false
#### Generate Predictions ####
# Add Bayesian model predictions
analysis_data <- analysis_data %>%
  mutate(predicted_price_bay = predict(bayesian_model, newdata = analysis_data))
# Add Linear regression model predictions
analysis_data <- analysis_data %>%
  mutate(predicted_price_linear = predict(linear_regression_model, newdata = analysis_data))

# View the updated dataset
head(analysis_data)
```

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-model-predict
#### Plot the Model 
# Plot for Bayesian model
ggplot(analysis_data, aes(x = current_price, y = predicted_price_bay)) +
  geom_point(color = "blue", alpha = 0.6) +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  labs(
    title = "Actual vs Predicted Prices (Bayesian Model)",
    x = "Actual Price",
    y = "Predicted Price"
  ) +
  theme_minimal()

# Plot for Linear model
ggplot(analysis_data, aes(x = current_price, y = predicted_price_linear)) +
  geom_point(color = "purple", alpha = 0.6) +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  labs(
    title = "Actual vs Predicted Prices (Linear Model)",
    x = "Actual Price",
    y = "Predicted Price"
  ) +
  theme_minimal()
```
The following graph shows that the forecasting price of the Bayesian model is closely concentrated near the straight line, especially in the lower price range($2.75-$3.125), and the actual price and the predicted value show a high degree of consistency. When the actual price is higher, the model becomes underestimated, indicating that it has limitations in capturing high price outliers. Generally speaking, the Bayesian model is more flexible and good at capturing the values in the dynamic economic market. The second one indicates the distribution of the predicted price of the linear regression model and the values around the straight line is relatively scattered, and the prediction accuracy is lower than that of the Bayesian model. And the model failed to accurately capture the abnormal values. The linear regression model assumes that there is a fixed relationship between the predictor and the response variable, which is difficult to adapt to nonlinear dynamics.

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-residual-distri
# Calculate Residuals
analysis_data <- analysis_data %>%
  mutate(
    residual_bay = current_price - predicted_price_bay,
    residual_linear = current_price - predicted_price_linear
  )

# Plot Residuals
residual_data <- analysis_data %>%
  pivot_longer(cols = c(residual_bay, residual_linear), names_to = "model", values_to = "residual") %>%
  mutate(model = recode(model, "residual_bay" = "Bayesian", "residual_linear" = "Linear"))

ggplot(residual_data, aes(x = residual, fill = model)) +
  geom_histogram(alpha = 0.6, position = "identity", bins = 20) +
  labs(
    title = "Residual Distribution for Bayesian and Linear Models",
    x = "Residual",
    y = "Count",
    fill = "Model"
  ) +
  theme_minimal()

# Residuals vs. Predicted Values for Bayesian Model
ggplot(analysis_data, aes(x = predicted_price_bay, y = residual_bay)) +
  geom_point(alpha = 0.6, color = "blue") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(
    title = "Residuals vs Predicted Values (Bayesian Model)",
    x = "Predicted Price",
    y = "Residual"
  ) +
  theme_minimal()

# Residuals vs. Predicted Values for Linear Model
ggplot(analysis_data, aes(x = predicted_price_linear, y = residual_linear)) +
  geom_point(alpha = 0.6, color = "purple") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(
    title = "Residuals vs Predicted Values (Linear Model)",
    x = "Predicted Price",
    y = "Residual"
  ) +
  theme_minimal()
```
The graph above show residuals of Bayesian model are closely concentrated near zero, indicating that the prediction accuracy of most data points is high. Although most of the residuals in the linear model are close to zero, there is a significant long tail in the positive residual, reflecting the poor prediction effect of some observations. In general, the residual distribution of the Bayesian model is more symmetrical and concentrate, indicating that the deviation is smaller and the prediction is more reliable.

In terms of the following residuals vs. predicted values plot, the residuals of the Bayesian model is well distributed around the red line, and there is no obvious pattern, which shows that the model fits well. A small number of large residuals show that the Bayesian model is slightly insufficient in dealing with outliers, but the overall performance is still strong. Compared with the Bayesian model, the linear model has a more scattered residual distribution, especially in the area of higher predicted values. The residuals of some predicted prices are large, indicating that the linear model is not flexible enough in capturing complex relationships.

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
# Calculate RMSE for both models
rmse_bayesian <- sqrt(mean((analysis_data$current_price - analysis_data$predicted_price_bay)^2))
rmse_linear <- sqrt(mean((analysis_data$current_price - analysis_data$predicted_price_linear)^2))

cat("RMSE for Bayesian Model:", rmse_bayesian, "\n")
cat("RMSE for Linear Model:", rmse_linear, "\n")
```

```{r}
#| label: fig-bay-ci
#| eval: true
#| echo: false
#| message: false
#| warning: false

# Extract Bayesian credible intervals
bayesian_intervals <- posterior_predict(bayesian_model, newdata = analysis_data, draws = 1000)
bayesian_ci <- apply(bayesian_intervals, 2, quantile, probs = c(0.025, 0.975))

# Add to data
analysis_data <- analysis_data %>%
  mutate(
    bayesian_ci_lower = bayesian_ci[1, ],
    bayesian_ci_upper = bayesian_ci[2, ]
  )

# Plot Credible Intervals
ggplot(analysis_data, aes(x = current_price, y = predicted_price_bay)) +
  geom_point(color = "blue", alpha = 0.6) +
  geom_errorbar(aes(ymin = bayesian_ci_lower, ymax = bayesian_ci_upper), color = "orange", width = 0.2) +
  labs(
    title = "Bayesian Credible Intervals for Predicted Prices",
    x = "Actual Price",
    y = "Predicted Price"
  ) +
  theme_minimal()
```

@fig-bay-ci shows the uncertainty of price forecasting through forecast values and 90% confidence intervals, providing decision-makers with rich forecasting information. It helps to evaluate the reliability and potential risks of price forecasting, especially in the uncertain scenario of price freezing. In contrast, the linear model lacks the ability to deal with uncertainty and outliers, and it is difficult to meet the needs of taking pricing strategies in the dynamic market. Therefore, the Bayesian model is superior in price freeze analysis.

### Model justification

# Results

There is a significant pattern between the current price (current_price) with the old price (old_price) and price per unit(price_per_unit). The Bayesian model incorporates uncertainty when estimating the impact of these predictors on price. The following table summarizes the coefficient estimates and shows the reliability of these estimates through the 90% confidence interval.

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: smy-bay-model
# Load the Bayesian model
bayesian_model <- readRDS("~/Desktop/grocery_price_freeze/models/bayesian_model.rds")

# Print summary of the model to inspect the results
print(summary(bayesian_model))
```

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: tbl-coeff-est
# Generate a data frame of the coefficient summary
model_summary_df <- data.frame(
  Parameter = c("Intercept", "Current Price", "Old Price"),
  Mean = c(3.56, 1.78, 0.72),
  SD = c(0.17, 0.14, 0.12),
  `2.5%` = c(3.23, 1.50, 0.50),
  `50%` = c(3.55, 1.78, 0.72),
  `97.5%` = c(3.89, 2.06, 0.94)
)

# Display table with kable
kable(model_summary_df, format = "markdown", align = "c", col.names = c("Parameter", "Mean", "SD", "2.5%", "50%", "97.5%"))
```
@tbl-coeff-est provides the coefficient estimates for current_price and old_price, with a baseline intercept.

The intercept shows that the price forecast has a strong starting point, and the average coefficient of the current price shows a significant positive correlation, indicating that the price level is strongly affected by its latest state. This result shows that the pricing trend is continuous and emphasizes the importance of current price in forecasting. The positive coefficient of the old price was 0.72(smaller than 1.78 for current price), indicating that the historical price trend has also played a certain role in predicting the price, but its impact is smaller than that of the current price. This shows that although old prices have contributed to forecasts in the future, their impact is relatively limited.

To visualize the uncertainty around the coefficient estimates, the following graph displays the 90% credible intervals for current_price and old_price.
```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-model_coefficients

# Extract posterior samples
posterior_samples <- as.array(bayesian_model)

# Plot 90% credible intervals for the coefficients
color_scheme_set("brightblue")
mcmc_intervals(
  posterior_samples,
  prob = 0.9
) +
  labs(
    title = "Model Coefficients",
    subtitle = "90% Credible Intervals",
    x = "Coefficient Estimate",
    y = "Predictors"
  ) +
  theme_minimal()

```

@fig-model_coefficients provides an a posterior mean estimate and a credible interval, which comprehensively demonstrates the impact of price per unit and old price on pricing. The price_per_unit, which also reflects the latest pricing strategies, has a greater impact, highlighting its future importance of price prediction. Although the impact of the old price is relatively small, it still shows a positive impact, indicating that the old price affects the future pricing to a certain extent, but the effect is relatively weak.
The confidence interval shows the accuracy and variability of these estimates.

# Discussion


## Weaknesses and next steps
On the whole, the Bayesian model performs well in most price ranges, but a few large residuals indicate that the Bayesian model is slightly insufficient in dealing with outliers. Although it reflects the solid handling of uncertainty during the price freeze, the small peaks in the high price range are insufficiently captured. It may be improved by introducing more predictive variables. And before using the Bayesian model, it is necessary to reduce the data sample to a certain value in order to accurately compare the fitting performance of the Bayesian model and the linear model, which will lead to insufficient samples and possible predictive deviations. In future research, it is necessary to consider the screening of data before fitting the model.


\appendix

# Appendix 


# Additional data details

## Posterior predictive check

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]
#### Posterior Predictive Check ####
# Draw samples from the posterior predictive distribution
pp_check(bayesian_model, nsamples = 100) +
  ggtitle("Posterior Predictive Check: Distribution of Current Price")

```
@fig-ppcheckandposteriorvsprior (PPC) shows that the Bayesian model can well show the distribution characteristics of the current price and reflect its reliability in price prediction. The observation data is highly consistent with the central trend of the simulation data, indicating that the model accurately captures the overall shape of the main price range.However, there are certain limitations on the modelling of extreme values or abnormal values. The tail of the simulation distribution is slightly beyond the scope of observation data, indicating that the model tries to incorporate potential outliers or incompletely reflected variability.

## Diagnostics

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-diagnostics
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2
plot(bayesian_model, "trace")

plot(bayesian_model, "rhat")

```
@fig-diagnostics shows that the Bayesian model has successfully achieved convergence, ensuring that the exploration of the posterior distribution is sufficient and the inference is reliable. In the trace diagram, each parameter shows well-mixed chains, with the samples overlapping and moving freely across the parameter space without sticking. In addition, the chain presents a stable state with no obvious drift or trend, indicating that the sampling process has reached convergence. 
At the same time, the graph shows the values of the parameters are very close to 1, indicating that the difference between the with-chain variance and the between-chain variance is extremely small, which further verifies the convergence of the chain. These results show that the sampling process is sufficient and the posteriori distribution is fully explored. And the reliability of the model can provide a solid basis for parameter analysis and price forecasting during the price freeze. The stability and low r values provide strong support for subsequent inferences and decision-making, ensuring that the model results are credible and suitable for pricing analysis in actual situations.


## Pollster Methodology

The polling method of this study focuses on designing a systematic process to collect price data of whole wheat bread from Canadian vendors during the price freeze from November to February of the following year. 

The survey aims to study whether the price freeze policy was prosecuted by the major Canadian grocery suppliers from November to February of the following year. We took suppliers and consumers in the target group, and major grocery chain stores such as Loblaws, Metro, No Frills, Save-On-Foods, T&T and Voila were all included in the data collection of the survey.

The questionnaire adopts stratified sampling technology, which can ensure that the data is collected proportionally from different suppliers and regions, and through random sampling to reduce deviation and ensure diversity.

We can also distribute online questionnaires by email and social media advertisements, but physical store data needs to be collected in advance through the on-site survey team, so as to verify the results of the questionnaire. In addition, the team can also collect and supplement data from the supplier's official website to ensure the comprehensiveness and accuracy of the data.

The design of the questionnaire needs to be concise and clear, and provide detailed record descriptions for different product categories.

Finally, in the process of data processing, we prove that the data quality is reliable by marking and processing outliers, and cross-verifying the data reported by suppliers and consumers. This multi-level survey design and strict data processing method are conducive to a comprehensive and accurate analysis of the implementation of the price freeze policy and provide a basis for policy formulation and consumers.

## Idealized Methodology
In order to ensure the accuracy, reliability and reproducibility of data collection and analysis, this idealization method is specially designed, which is more comprehensive and complete than the former. First of all, consider covering the entire market, including all Canadian suppliers, online platforms and small independent grocery stores, to ensure that the market situation of the product(whole wheat bread) is fully reflected. In terms of data collection step, add the data sets from multiple data sources, including data captured from the real-time network (the latest real-time prices can be obtained), historical archives and transaction data of each grocery store, and combined with third-party data sets (official analysis data used) for background comparison.

In terms of technology, multi-level sampling can be used and the sampling scale can be adjusted to improve the representativeness of areas with insufficient data coverage. In cases such as inflation shocks or market fluctuations, we use simulation-based methods to test the reliability of the data and link the survey results with the Bayesian model to optimize the forecast and improve the accuracy of the model.

We also need to consider data ethics and transparency. We need to disclose the data collection protocol and implement anonymization. This method can not only capture accurate and detailed price data, but also set industry benchmarks for observation data collection, thus providing high-value operational insights.

## Designing a Survey for Grocery Pricing Data Collection
### Objective
The objective of the survey is to collect detailed price data of grocery products(whole wheat bread) from multiple Canadian suppliers to evaluate and predict their compliance with the price freeze strategy from November to February of the following year. These data will provide references for price changes, outliers and trends, and will become the basis for statistical analysis and Bayesian analysis.

# Survey and design

### Target respondents

Managers of food grocery stores:
Responsible for the pricing of the whole wheat bread from suppliers

Consumers:
Consumers who regularly buy food and groceries can get the price through receipts.

Online shopping platform managers:
Price information can be collected from the online food and grocery platform.

### Data collection method
Design structured online and offline questionnaires and distribute them to the target respondents. Also, obtain additional price data from the supplier's official website to verify the data and expand the data range.

### Questionnaire content

Part I: Basic Information

What is your region?

What is your identity? 
Choice: 
1. relevant food and grocery store staff
2. consumers
3. others

Part II: Supplier Information

What is the food and grocery supplier you visited? 
Choice: 
1. Loblaws
2. Metro
3. No Frills
4. Save-On-Foods
5. T&T
6. Voila 
7. other

What form is the store?

1. physical store

2. online store

3. others 

Part III: Product price

Please list the prices of the following products:

[Name of whole wheat bread 1]

[Name of whole wheat bread 2]

[Name of whole wheat bread 3]


Part IV: Historical Price

Do you have the historical price data of these products? If so, please provide the following information:

Product name:

Last month's price:

Price 3 months ago:

Part VI: Price Freeze Observation

Have you noticed that the price of the above products has been frozen? ( Yes/No)

Have you observed any price fluctuations or promotional activities? 
1. price for the single product decrease
2. price for the single product increase
3. price unchanged
4. price unchanged for the single product but got promotion for buying greater than 2

### Sample strategy
Sample frame:
Major food and grocery suppliers in Canada, and consumer samples from different cities.

Sample extraction method:
Stratified sampling
Random sampling

Sample scale:
1,000-1,500 questionnaires 

### Data verification

Cross-verification by the price reported by the consumer with the data reported by the supplier and the official online price.

### Ethic considerations

Before collecting data, the consent of the interviewee is required to ensure data privacy. Also, anonymize the respondent's information.

By integrating the principle of observing data collection and ensuring the methodology, this questionnaire can provide high-quality data support for subsequent analysis.

\newpage


# References


